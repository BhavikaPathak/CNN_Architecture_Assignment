{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clCJNmCGQNyy"
      },
      "source": [
        "# **TOPIC: Understanding Pooling and Padding in CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9Ewd2HQZrV"
      },
      "source": [
        "## ANSWER 1\n",
        "**Pooling in CNN:**\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        " Pooling is a downsampling operation in Convolutional Neural Networks (CNNs) that reduces the spatial dimensions of the input feature maps. The primary purpose is to progressively reduce the spatial size, which helps in controlling the number of parameters and computations in the network. This, in turn, helps in preventing overfitting and reducing the computational load.\n",
        "\n",
        "**Benefits:**\n",
        "\n",
        "Translation Invariance: Pooling makes the network less sensitive to the spatial location of features, providing a degree of translation invariance.\n",
        "\n",
        "Reduced Computational Complexity: Pooling reduces the number of parameters and computations in the network, making it computationally more efficient.\n",
        "\n",
        "Feature Hierarchy: Successive pooling layers help create a hierarchical representation of features, capturing both local and global information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z18yj4DUQ-Cu"
      },
      "source": [
        "## ANSWER 2\n",
        "\n",
        "**Max Pooling:**\n",
        "\n",
        " It selects the maximum value from the group of values within the pooling window. Max pooling is effective in capturing the most prominent feature in a local region.\n",
        "\n",
        "**Min Pooling:**\n",
        "\n",
        " It selects the minimum value from the group of values within the pooling window. Min pooling can be less common and is used to capture the least prominent feature in a local region. It may be useful in certain scenarios where highlighting the least intense features is important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfZMIFxeRQjx"
      },
      "source": [
        "## ANSWER 3\n",
        "\n",
        "**Padding in CNN:**\n",
        "\n",
        "**Concept:**\n",
        "\n",
        " Padding involves adding extra border pixels to the input feature map, allowing the convolutional filters to process the pixels at the image boundaries. This is important to prevent the reduction in spatial dimensions and loss of information during convolutional operations.\n",
        "\n",
        "**Significance:**\n",
        "\n",
        "Preservation of Spatial Information: Padding ensures that the spatial dimensions of the input are maintained after convolution, preventing information loss.\n",
        "\n",
        "Edge and Corner Pixel Treatment: Without padding, the pixels at the edges and corners of the input feature map would be underrepresented in the output, impacting the network's ability to capture features at these locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni2j42TUR1eY"
      },
      "source": [
        "## ANSWER 4\n",
        "**Zero-padding:**\n",
        "\n",
        "Effect on Output Size: Increases the spatial dimensions of the feature map by adding zeros around the input.\n",
        "\n",
        "Advantage: Preserves spatial information at the borders and corners of the input.\n",
        "\n",
        "Commonly Used: Often used to ensure that the output feature map has the same spatial dimensions as the input.\n",
        "\n",
        "**Valid-padding:**\n",
        "\n",
        "Effect on Output Size: Does not add any extra padding to the input, resulting in a smaller output size compared to the input.\n",
        "\n",
        "Advantage: Reduces the computational load and the risk of overfitting.\n",
        "\n",
        "Commonly Used: Frequently used when the spatial dimensions can be reduced without significant loss of information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtn9ExE0SIhH"
      },
      "source": [
        "#**TOPIC: Exploring LeNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbGnSOchULO6"
      },
      "source": [
        "## ANSWER 1\n",
        "**Overview of LeNet-5 Architecture:**\n",
        "\n",
        "LeNet-5 is a pioneering convolutional neural network (CNN) architecture developed by Yann LeCun and his collaborators in the late 1990s. It was designed for handwritten digit recognition tasks and played a significant role in the development of deep learning for computer vision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KKfD0-gUTLq"
      },
      "source": [
        "## ANSWER 2\n",
        "**Key Components of LeNet-5:**\n",
        "\n",
        "**Convolutional Layers:**\n",
        "\n",
        "LeNet-5 consists of multiple convolutional layers, each followed by a subsampling (pooling) layer. These layers are responsible for learning hierarchical features from the input data.\n",
        "\n",
        "**Fully Connected Layers:**\n",
        "\n",
        "After the convolutional and pooling layers, LeNet-5 has fully connected layers for high-level reasoning and decision-making.\n",
        "\n",
        "**Activation Functions:**\n",
        "\n",
        "Tanh and sigmoid activation functions are used in different layers of LeNet-5 to introduce non-linearity and enable the network to learn complex patterns.\n",
        "\n",
        "**Pooling Layers:**\n",
        "\n",
        "LeNet-5 uses average pooling in some layers to reduce spatial dimensions and introduce translation invariance.\n",
        "\n",
        "**Softmax Layer:**\n",
        "\n",
        "The final layer is a softmax layer that produces the output probabilities for each class, making it suitable for multi-class classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBOO3u8DU9_9"
      },
      "source": [
        "## ANSWER 3\n",
        "**Advantages and Limitations of LeNet-5:**\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "Pioneering Architecture: LeNet-5 laid the foundation for modern CNNs and demonstrated the effectiveness of convolutional layers for feature extraction.\n",
        "\n",
        "Applicability: While initially designed for digit recognition, LeNet-5's principles have been applied to various image classification tasks.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "Simplicity: Due to its age, LeNet-5 may lack the depth and complexity of more recent architectures, potentially limiting its performance on highly complex tasks.\n",
        "\n",
        "Limited Capacity: In comparison to more recent CNNs, LeNet-5 may struggle with capturing intricate patterns in large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JJ5oTIEVQR"
      },
      "source": [
        "## ANSWER 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haaIvuEXFovg"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D,MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04glWr20OTvQ"
      },
      "source": [
        "**Load MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szXkodEnQMU6"
      },
      "outputs": [],
      "source": [
        "(X_train , y_train ) , (X_test , y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPe0I2SaOad4"
      },
      "source": [
        "**Preprocess MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUTgMB9PFxco"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAnglTTyGJnD"
      },
      "outputs": [],
      "source": [
        "X_test = X_test /255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEJUOF1sOi-j"
      },
      "source": [
        "**Encode the labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM6ZhgO0Gq5T"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb5RHKSsOsP9"
      },
      "source": [
        "**Build LeNet-5 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNYK1H4GGys2"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6,kernel_size = (5,5),padding ='valid',activation='tanh',input_shape =(28,28,1)))\n",
        "model.add(AveragePooling2D(pool_size = (2,2) , strides = 2 , padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(16,kernel_size = (5,5) , padding = 'valid', activation ='tanh'))\n",
        "model.add(AveragePooling2D(pool_size = (2,2),strides = 2 , padding = 'valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120,activation='tanh'))\n",
        "model.add(Dense(84,activation='tanh'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB-YY80qOxY4"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFlhDPL3G1sf",
        "outputId": "7fe75ca6-2112-4cc8-f05e-4973f68bc455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_6 (Avera  (None, 12, 12, 6)         0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_7 (Avera  (None, 4, 4, 16)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44426 (173.54 KB)\n",
            "Trainable params: 44426 (173.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5ZSsH7O5UA"
      },
      "source": [
        "**Compiling the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9DTS5LaIky2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rsAJH5dO_wI"
      },
      "source": [
        "**Traning the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YM_vputIrB4",
        "outputId": "aa8790c9-d35a-4f8c-afeb-c00f9e4c8c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 25s 28ms/step - loss: 0.3076 - accuracy: 0.9091 - val_loss: 0.1129 - val_accuracy: 0.9675\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 21s 25ms/step - loss: 0.1097 - accuracy: 0.9669 - val_loss: 0.0732 - val_accuracy: 0.9802\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 23s 28ms/step - loss: 0.0728 - accuracy: 0.9774 - val_loss: 0.0650 - val_accuracy: 0.9802\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 23s 27ms/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 22s 26ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.0529 - val_accuracy: 0.9848\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce01ee7e590>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b6Ge_fKPNVZ"
      },
      "source": [
        "**Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOgFU7lqJCdG",
        "outputId": "807534c0-4e20-46ad-9ca9-d7e5fcc23285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 2s - loss: 0.0477 - accuracy: 0.9854 - 2s/epoch - 6ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ngPKSk7G6aJ",
        "outputId": "6ce4ae4e-5b8b-4977-e721-84248528f4d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy :  98.54000210762024 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy : \",test_acc*100 ,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv28UEf3PyEC"
      },
      "source": [
        "#**TOPIC: Analyzing AlexNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zl_t1-sRHEZ"
      },
      "source": [
        "## ANSWER 1\n",
        "**Overview of AlexNet Architecture:**\n",
        "\n",
        "AlexNet is a deep convolutional neural network architecture designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It gained significant attention and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 by achieving a considerable improvement in image classification accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1BkFRzLSVoQ"
      },
      "source": [
        "## ANSWER 2\n",
        "**Architecture Innovations in AlexNet:**\n",
        "\n",
        "Depth and Width: AlexNet was one of the first deep CNNs, consisting of eight layers, including five convolutional layers and three fully connected layers. This depth allowed the model to learn hierarchical features.\n",
        "\n",
        "ReLU Activation: AlexNet used Rectified Linear Units (ReLU) as the activation function, which helped mitigate the vanishing gradient problem and accelerate convergence.\n",
        "\n",
        "Local Response Normalization (LRN): LRN was applied after the ReLU activation to enhance the model's ability to generalize by normalizing responses across adjacent channels.\n",
        "\n",
        "Overlapping Pooling: The pooling layers utilized overlapping regions, unlike traditional max-pooling, providing richer spatial hierarchies.\n",
        "\n",
        "Data Augmentation and Dropout: AlexNet employed data augmentation (such as random cropping and flipping) during training to reduce overfitting. Dropout, a regularization technique, was applied to fully connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6E0TBcdSNK9"
      },
      "source": [
        "## ANSWER 3\n",
        "**Role of Convolutional Layers, Pooling Layers, and Fully Connected Layers:**\n",
        "\n",
        "Convolutional Layers: The convolutional layers in AlexNet are responsible for learning hierarchical features from the input image. These layers use filters to convolve across the input, capturing patterns and features.\n",
        "\n",
        "Pooling Layers: Max-pooling layers in AlexNet help downsample the spatial dimensions of the feature maps, reducing computational complexity and introducing some degree of translation invariance. Overlapping pooling was used to increase spatial hierarchies.\n",
        "\n",
        "Fully Connected Layers: The fully connected layers at the end of the network capture high-level reasoning and make predictions based on the features learned by the convolutional and pooling layers. These layers enable the model to make class predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIXW3shOSn4t"
      },
      "source": [
        "## ANSWER 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl0wQQunbcAZ",
        "outputId": "78ca7966-d702-4b20-9232-82eb609e179b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl5uLDlcUYVA",
        "outputId": "759b8028-96b6-49c8-c507-f823456732cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/107.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (9.4.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127283 sha256=df42014eaca9f28771489b713dba9bd6bddf08a8267b7154554bc72fba2709bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/fb/7b/e06204a0ceefa45443930b9a250cb5ebe31def0e4e8245a465\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tflearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2QjO9b2PP2Cj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kD4k4WB6UMC8"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load cifar10 dataset**"
      ],
      "metadata": {
        "id": "uK1IEiFBDmbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ule71XUsYPoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97471ad-0bfe-4d16-a18c-0cd9138677eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train , y_train ) , (X_test , y_test) = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess CIFAR10 dataset**"
      ],
      "metadata": {
        "id": "YWmaNBlWD095"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XvExO9BLY5Jt"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "usuKsB2gZA5D"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode the labels**"
      ],
      "metadata": {
        "id": "uuA1fLAdD_8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ryxa1RiiZF61"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build AlexNet Model**"
      ],
      "metadata": {
        "id": "0TXiS1_3EDJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T9L1S0aab2Yy"
      },
      "outputs": [],
      "source": [
        "# Create a sequential model\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vLny8JlGb8AS"
      },
      "outputs": [],
      "source": [
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MrZZfMinb9j4"
      },
      "outputs": [],
      "source": [
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5),strides=(1,1),  padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bp7Lc8U2crS3"
      },
      "outputs": [],
      "source": [
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JkgAbWljcupI"
      },
      "outputs": [],
      "source": [
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jJxQpkOpc0a2"
      },
      "outputs": [],
      "source": [
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e95AzhKGc7iP"
      },
      "outputs": [],
      "source": [
        "# Passing it to a dense layer\n",
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cP5ZBJOTc_3R"
      },
      "outputs": [],
      "source": [
        "# 1st Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tkxXf7k_dECF"
      },
      "outputs": [],
      "source": [
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_cNI1HVXdHN8"
      },
      "outputs": [],
      "source": [
        "# Add Dropout\n",
        "model.add(Dropout(0.5))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CFxcXBy7ZMXe"
      },
      "outputs": [],
      "source": [
        "# Output Layer\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Summary**"
      ],
      "metadata": {
        "id": "UfJLVy5tEPPA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zXzZykzaqWS",
        "outputId": "bc96e4b6-4a79-4ccd-aa45-c93acf24cad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 6, 6, 96)          34944     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 6, 6, 96)          0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 2, 2, 96)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 2, 2, 96)          384       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 2, 2, 256)         614656    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 256)         1638656   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 1, 1, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 1, 384)         885120    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 1, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1, 1, 384)         1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 1, 1, 384)         1327488   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1, 1, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 1, 1, 384)         1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 1, 1, 256)         884992    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 1, 1, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              1052672   \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23299082 (88.88 MB)\n",
            "Trainable params: 23279946 (88.81 MB)\n",
            "Non-trainable params: 19136 (74.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling The Model**"
      ],
      "metadata": {
        "id": "lYv31nRQET3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NzEl-27DdNUO"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "oafF5gFNEgRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o2WKPp7dXx2",
        "outputId": "c5407c54-e40d-4edd-e9ae-5a9aa3c9795b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 815s 3s/step - loss: 2.2222 - accuracy: 0.2971 - val_loss: 1.9881 - val_accuracy: 0.2866\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 807s 3s/step - loss: 1.7745 - accuracy: 0.3989 - val_loss: 1.9922 - val_accuracy: 0.3404\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 819s 3s/step - loss: 1.6397 - accuracy: 0.4379 - val_loss: 1.9478 - val_accuracy: 0.4049\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 800s 3s/step - loss: 1.5338 - accuracy: 0.4733 - val_loss: 1.7426 - val_accuracy: 0.3944\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 809s 3s/step - loss: 1.5010 - accuracy: 0.4893 - val_loss: 1.7027 - val_accuracy: 0.4080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c30b6aadde0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Train\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the model**"
      ],
      "metadata": {
        "id": "x7l77WEMEd8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P3O6LmhGdo93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfb5aca-5b92-4773-bbb4-3ffaeb1d76e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 17s - loss: 1.6939 - accuracy: 0.4155 - 17s/epoch - 53ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IEPLqXy3dvji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03dbb603-de4c-442b-a67f-e8044e5b6ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy :  41.54999852180481 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy : \",test_acc*100 ,\"%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}